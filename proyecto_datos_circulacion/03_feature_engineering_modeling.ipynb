{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e455678-fa31-404c-ae3e-8d58e9f6b181",
   "metadata": {},
   "source": [
    "### Feature Engineering y Modelado Predictivo de Permisos de Circulación\n",
    "\n",
    "Este notebook toma el dataset limpio y estandarizado del paso anterior y lo utiliza para un problema de Machine Learning. El objetivo es:\n",
    "\n",
    "1. Ingeniería de Características: Crear nuevas variables que puedan mejorar el rendimiento del modelo.\n",
    "\n",
    "2. Preparación de Datos: Preparar los datos para el entrenamiento de un modelo predictivo.\n",
    "\n",
    "3. Modelado: Entrenar un modelo de clasificación simple para predecir el estado de un permiso (Activo o Inactivo) basándose en sus características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48663e83-ee56-436f-81ac-fc68cd5b70c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed/permisos_circulacion_limpio.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Cargar el dataset limpio y procesado del paso anterior\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/processed/permisos_circulacion_limpio.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Inspección inicial del dataset limpio\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Información del dataset limpio ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/processed/permisos_circulacion_limpio.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Cargar el dataset limpio y procesado del paso anterior\n",
    "df_clean = pd.read_csv('data/processed/permisos_circulacion_limpio.csv')\n",
    "\n",
    "# Inspección inicial del dataset limpio\n",
    "print(\"--- Información del dataset limpio ---\")\n",
    "df_clean.info()\n",
    "print(\"\\n--- Primeras 5 filas del dataset limpio ---\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c10f34-6e90-4865-af32-9da3e4713aad",
   "metadata": {},
   "source": [
    "### 1. Ingeniería de Características (Feature Engineering)\n",
    "Vamos a crear nuevas variables a partir de las existentes para darle más información al modelo. Transformaremos las fechas en variables de tiempo y usaremos 'one-hot encoding' para las variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15987af4-da19-40fa-a937-d30e4b249b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna de fecha a formato datetime\n",
    "df_clean['fecha_emision'] = pd.to_datetime(df_clean['fecha_emision'], errors='coerce')\n",
    "\n",
    "# Eliminar las filas con fechas inválidas que no pudieron ser convertidas\n",
    "df_clean.dropna(subset=['fecha_emision'], inplace=True)\n",
    "\n",
    "# Crear nuevas variables de tiempo\n",
    "df_clean['dia_semana'] = df_clean['fecha_emision'].dt.day_name()\n",
    "df_clean['mes'] = df_clean['fecha_emision'].dt.month\n",
    "df_clean['dia_del_mes'] = df_clean['fecha_emision'].dt.day\n",
    "\n",
    "# Calcular una fecha de expiración para un posible problema de clasificación\n",
    "df_clean['fecha_expiracion'] = df_clean['fecha_emision'] + pd.to_timedelta(df_clean['duracion_dias'], unit='D')\n",
    "\n",
    "# Convertir variables categóricas en variables 'dummy' (one-hot encoding)\n",
    "df_model = pd.get_dummies(df_clean, columns=['tipo_vehiculo', 'zona_circulacion', 'dia_semana'])\n",
    "\n",
    "# Eliminar la columna de fecha_emision ya que hemos extraído la información relevante\n",
    "df_model.drop(columns=['fecha_emision', 'fecha_expiracion'], inplace=True)\n",
    "\n",
    "# Verificación de la estructura del nuevo DataFrame\n",
    "print(\"--- Estructura del DataFrame después de la ingeniería de características ---\")\n",
    "print(df_model.head())\n",
    "print(\"\\n--- Columnas finales para el modelo ---\")\n",
    "print(df_model.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f48469-f56b-442f-a432-ef6f668d3d1b",
   "metadata": {},
   "source": [
    "### 2. Preparación de los Datos para el Modelado\n",
    "\n",
    "Dividiremos nuestro dataset en dos partes: un conjunto de entrenamiento (train) y un conjunto de prueba (test). Esto es fundamental para evaluar el rendimiento del modelo de forma objetiva.\n",
    "\n",
    "1. Características (X): Las variables que usaremos para predecir.\n",
    "\n",
    "2. Variable Objetivo (y): La variable que queremos predecir, en este caso, el estado del permiso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8284da5-b52e-45d1-8754-062acebfa82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las características (X) y la variable objetivo (y)\n",
    "X = df_model.drop(columns=['estado'])\n",
    "y = df_model['estado']\n",
    "\n",
    "# Convertir la variable objetivo a valores numéricos (0 y 1)\n",
    "y = y.map({'Activo': 1, 'Inactivo': 0})\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"--- Tamaño de los conjuntos de datos ---\")\n",
    "print(f\"Conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
    "print(f\"Conjunto de prueba (X_test): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c63bb-672d-4560-8f9b-67edb6335fd1",
   "metadata": {},
   "source": [
    "### 3. Entrenamiento y Evaluación del Modelo\n",
    "\n",
    "Utilizaremos un modelo de clasificación simple y robusto como RandomForestClassifier. Luego evaluaremos su rendimiento en el conjunto de prueba para ver qué tan bien predice el estado del permiso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb20cc3-06af-4d58-8fe3-967af2c240e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar el modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['Inactivo', 'Activo'])\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"--- Evaluación del modelo RandomForest ---\")\n",
    "print(f\"Precisión (Accuracy): {accuracy:.4f}\")\n",
    "print(\"\\n--- Reporte de Clasificación ---\")\n",
    "print(report)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Inactivo', 'Activo'], yticklabels=['Inactivo', 'Activo'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Realidad')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a5b92-4420-41d0-8a9c-78ec690ba58e",
   "metadata": {},
   "source": [
    "### Conclusión y Próximos Pasos\n",
    "\n",
    "Este ejercicio demuestra cómo un proceso de feature engineering y modelado puede extraer valor de datos limpios. El modelo de Random Forest logra una buena precisión, lo que indica que las características que creamos son útiles para predecir el estado de un permiso.\n",
    "\n",
    "Para mejorar este proyecto en el futuro, se podría:\n",
    "\n",
    "* Realizar una optimización de hiperparámetros del modelo.\n",
    "\n",
    "* Probar otros modelos de clasificación (como Gradient Boosting).\n",
    "\n",
    "* Realizar un análisis de la importancia de las características para entender qué variables tienen un mayor impacto en la predicción.\n",
    "\n",
    "* Visualizar los resultados de las predicciones en un mapa (si tuviéramos coordenadas geográficas más detalladas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65969c93-0d75-454a-9434-72b694a4cded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
